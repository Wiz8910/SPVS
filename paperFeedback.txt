abstract
mentions lsi so we better do that in experiment

introduction
In related work i Implemented a different algorithm from the Fodeh paper. For the one I implemented
I'd describe it like "in Fodeh Documents are generalized individually based on distances to terms
present in the document. This is considerably slower than the other approaches which sanitize words
a single time across the whole document collection, but can be done in parallel"
I implemented the wrong fodeh my bad
Typo in second to last paragraph of section two
Should be
"Word sense disambiguation(WSD) is the task of choosing the appropriate meaning of a word based on
its usage."

3 Semantics-Preserving text representation
Say documents are represented by frequency but we are using tf-idf